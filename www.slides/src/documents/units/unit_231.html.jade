---
layout: 'deck_unit'
title: "Core Knowledge and Modularity"
tags: []
description: "How is core knowledge related to modularity?  Can we answer challenges to the very idea of core knowledge by appeal to Fodor’s account of modularity?"
depends: ['']
source: ['']
duration: 5
book: []
exercises: []
exercises_fast: []
---

include ../../../fragments/unit_mixins
include ../../../fragments/compatibility_mixins






+slide
  .notes: :t()
    The problems with core knowledge look like they might be 
    the sort of problem a philospoher might be able to help with.
  .notes: :t()
    Jerry Fodor has written a book called 'Modularity of Mind' about what he calls modules.
    And modules look a bit like core systems, as I'll explain.
    Further, Spelke herself has at one point made a connection.
    So let's have a look at the notion of modularity and see if that will help us.
  p core system = module?
  p.em-above.handout.notes.show ‘In Fodor’s (1983) terms, visual tracking and preferential looking each may depend on 
    span.module modular mechanisms
    span .’
  .handout.notes.ctd \citep[p.\ 137]{spelke:1995_spatiotemporal}
  p.right Spelke et al (1995, p. 137)
  +invert('.module')
  .notes So what is a modular mechanism?



// modularity
mixin fodor_on_modules(p)
  if typeof(p) === 'undefined'
    - p = {}
  if !('step' in p)
    - p.step = false
  if !('end' in p)
    -p.end = false
  - var bkg = 'modularity_photo_seq/Slide1.jpg'
  if p.end
    -  bkg = 'modularity_photo_seq/Slide5.jpg'
  img.bkg(src='/img/#{bkg}')
  +_slide_inner
    p Modules
    ol
      li they are ‘the psychological systems whose operations present the world to thought’;
      li they ‘constitute a natural kind’; and
      li there is ‘a cluster of properties that they have in common … [they are] domain-specific computational systems characterized by informational encapsulation, high-speed, restricted access, neural specificity, and the rest’ (Fodor 1983: 101)
    if p.step
      +attr('img.bkg','src:/img/modularity_photo_seq/Slide2.jpg')
      +attr('img.bkg','src:/img/modularity_photo_seq/Slide3.jpg')
      +attr('img.bkg','src:/img/modularity_photo_seq/Slide4.jpg')
      +attr('img.bkg','src:/img/modularity_photo_seq/Slide5.jpg')
    block

section.slide
  +fodor_on_modules({step:false, end:false})
  .notes Modules are widely held to play a central role in explaining mental development and in accounts of the mind generally.
  .notes Jerry Fodor makes three claims about modules:
  .handout \subsection{Modularity}
  .handout.notes Fodor’s three claims about modules:
  .handout.notes \begin{enumerate}
  .handout.notes \item they are ‘the psychological systems whose operations present the world to thought’;
  .handout.notes \item they ‘constitute a natural kind’; and
  .handout.notes \item there is ‘a cluster of properties that they have in common’ \citep[p.\ 101]{Fodor:1983dg}.
  .handout.notes \end{enumerate}

//-
  +slide({bkg:'modularity_photo_seq/Slide1.jpg'})
    p Modules
    ol
      li they are ‘the psychological systems whose operations present the world to thought’;
      li they ‘constitute a natural kind’; and
      li there is ‘a cluster of properties that they have in common … [they are] domain-specific computational systems characterized by informational encapsulation, high-speed, restricted access, neural specificity, and the rest’ (Fodor 1983: 101)

mixin properties_of_modules(p)
  if typeof(p) === 'undefined'
    - p = {}
  if !('step' in p)
    - p.step = false
  ul.no-bullet
    li
      strong domain specificity
      p modules deal with ‘eccentric’ bodies of knowledge
    li.limited-accessibility(class="p.step ? 'blur-text' : ''")
      strong(style='z-index:3') limited accessibility
      p(style='z-index:3')  representations in modules are not usually inferentially integrated with knowledge
    li(class="p.step ? 'blur-text' : ''")
      strong information encapsulation
      p modules are unaffected by general knowledge or representations in other modules
      .notes For something to be informationally encapsulated is for its operation to be unaffected by the mere existence of general knowledge or representations stored in other modules (Fodor 1998b: 127)
    li(class="p.step ? 'blur-text' : ''")
      strong innateness 
      p roughly, the information and operations of a module not straightforwardly consequences of learning
    if p.step
      +blur_('li:eq(0)')
      +unblur('li:eq(1)')
      +blur_('li:eq(1)')
      +unblur('li:eq(2)')
      +blur_('li:eq(2)')
      +unblur('li:eq(3)')
      +unblur('li')
  block

+slide
  .notes What are these properties?
  .handout.notes These properties include: 
  .handout.notes \begin{itemize}
  .handout.notes \item domain specificity (modules deal with ‘eccentric’ bodies of knowledge)
  .handout.notes \item limited accessibility (representations in modules are not usually inferentially integrated with knowledge)
  .handout.notes \item information encapsulation (modules are unaffected by general knowledge or representations in other modules)
  .handout.notes \item innateness (roughly, the information and operations of a module not straightforwardly consequences of learning; but see \citet{Samuels:2004ho}).
  .handout.notes \end{itemize}
  +properties_of_modules({step:true})



  
section.slide
  .notes: :t()
    We've seen something like this list of properties before ...
    Compare the notion of a core system with the notion of a module
  .notes: :t()
    The two definitions are different, but the differences are subtle enough that we don't want both.
    My recommendation: if you want a better definition of core system, adopt 
    core system = module as a working assumption and then look to research on modularity 
    because there's more of it.
  //- 
    .handout \subsection{Compare modularity}
    .handout Modules are ‘the psychological systems whose operations present the world to thought’; 
      | they ‘constitute a natural kind’; and 
      | there is ‘a cluster of properties that they have in common’ \citep[p.\ 101]{Fodor:1983dg}.
    .handout These properties include:
    .handout \begin{itemize}
    .handout \item domain specificity (modules deal with ‘eccentric’ bodies of knowledge)
    .handout \item limited accessibility (representations in modules are not usually inferentially integrated with knowledge)
    .handout \item information encapsulation (modules are unaffected by general knowledge or representations in other modules)
    .handout \item innateness (roughly, the information and operations of a module not straightforwardly consequences of learning; but see \citet{Samuels:2004ho}).
    .handout \end{itemize}
  .words: .container_12: .grid_5
    p ‘core systems are 
      ol
        li: span.innate largely innate, 
        li
          span.encapsulated  encapsulated
          span , and 
        li: span  unchanging, 
        li: span  arising from phylogenetically old systems 
        li: span  built upon the output of innate perceptual analyzers’ 
    p.right (Carey and Spelke 1996: 520)
  .slide
    .right-half-white
      .words: .container_12: .grid_6
        div(style='padding-right:1em;')
          p Modules are ‘the psychological 
            span.present-the-world(style='z-index:0;') systems whose operations present the world to thought
            span ’; 
            | they ‘constitute a natural kind’; and 
            | there is ‘a cluster of properties that they have in common’
          ol
            li: span.innate(style='z-index:0;')  innateness 
            li: span.encapsulated(style='z-index:0;')  information encapsulation 
            li: span  domain specificity 
            li: span  limited accessibility 
            li: span  ...
    +highlight('.innate', 'pink')
    +highlight('.encapsulated', 'blue')
    +highlight('ol:eq(0) li:eq(4) span, .present-the-world', 'forestgreen')

  
+slide
  p.notes.show Will the notion of modularity help us in meeting the 
    span.challenges challenges
    span  to the very idea of a core system? 
  +invert_('.challenges')
  .slide
    .notes Recall that the challenges were these:
    ul.notes.show.em-above
      li multiple definitions
      li mismatch of definition to application 
      li justification for definition by list-of-features
      li definition by list-of-features rules out explanation
    .notes: :t()
      Let’s go back and see what Fodor says about modules again ...

section.slide
  .notes: :t()
    Not all researchers agree about the properties of modules.  That they are 
    informationally encapsulated is denied by Dan Sperber and Deirdre Wilson (2002: 9), 
    Simon Baron-Cohen (1995) and some evolutionary psychologists (Buller and Hardcastle 2000: 309), 
    whereas Scholl and Leslie claim that information encapsulation is the essence of modularity 
    and that any other properties modules have follow from this one (1999b: 133; this also seems 
    to fit what David Marr had in mind, e.g. Marr 1982: 100-1).  According to Max Coltheart, 
    the key to modularity is not information encapsulation but domain specificity; he suggests 
    Fodor should have defined a module simply as 'a cognitive system whose application is domain 
    specific' (1999: 118).  Peter Carruthers, on the other hand, denies that domain specificity 
    is a feature of all modules (2006: 6).  Fodor stipulated that modules are 
    'innately specified' (1983: 37, 119), and some theorists assume that modules, 
    if they exist, must be innate in the sense of being implemented by neural regions 
    whose structures are genetically specified (e.g. de Haan, Humphreys and Johnson 2002: 207; 
    Tanaka and Gauthier 1997: 85); others hold that innateness is 'orthogonal' to modularity 
    (Karmiloff-Smith 2006: 568).  There is also debate over how to understand individual 
    properties modules might have (e.g. Hirschfeld and Gelman 1994 on the meanings of domain 
    specificity; Samuels 2004 on innateness).
  .notes: :t()
    In short, then, theorists invoke many different notions of modularity, each barely different 
    from others.  You might think this is just a terminological issue.  I want to argue that 
    there is a substantial problem: we currently lack any theoretically viable account of what 
    modules are.  The problem is not that 'module' is used to mean different things-after all, 
    there might be different kinds of module.  The problem is that none of its various meanings 
    have been characterised rigorously enough.  All of the theorists mentioned above except Fodor 
    characterise notions of modularity by stipulating one or more properties their kind of module 
    is supposed to have.  This way of explicating notions of modularity fails to support principled 
    ways of resolving controversy.
  .notes: :t()
    No key explanatory notion can be adequately characterised by listing properties because the 
    explanatory power of any notion depends in part on there being something which unifies its 
    properties and merely listing properties says nothing about why they cluster together.
  .notes: :t()
    So much the same objections which applied to the very notion of core knowledge 
    appear to recur for module.  But note one interesting detail ...
  +fodor_on_modules({step:true, end:false})
    +highlight-row('li:eq(1)')
    .notes: :t()
      Interestingly, Fodor doesn't define modules by specifying a cluster of properties 
      (pace Sperber 2001: 51); he mentions the properties only as a way of gesturing towards 
      the phenomenon (Fodor 1983: 37) and he also says that modules constitute a natural kind 
      (see Fodor 1983: 101 quoted above). 


  
+slide
  .notes So let me return to my question:
  p.notes.show Will the notion of modularity help us in meeting the 
    span.bkg-words-highlight-invert.challenges challenges
    span  to the very idea of a core system? 
    .notes Recall that the challenges were these:
    ul.notes.show.em-above
      li multiple definitions
      li mismatch of definition to application 
      li justification for definition by list-of-features
      li definition by list-of-features rules out explanation
  +highlight-row('li:eq(0), li:eq(2), li:eq(3)')
  .notes: :t()
    As far as the first, third and fourth (multiple definitions and 
    justification for definition by list-of-features and
    definition by list-of-features rules out explanation) problems go,
    everything rests on the idea that modules are a natural kind.
    I think this idea deserves careful scruitiny but as far as I know there's 
    only one paper on this topic, which is by me.
    I'm not going to talk about the paper here; let me leave it like this:
    if you want to invoke a notion of core knowledge or modularity,
    you have to reply to these problems.  And one way to reply to them---
    the only way I know---is to develop the idea that modules are a natural 
    kind.  If you want to know more ask me for my paper and I'll send it to you.
  +unhighlight-row_('li:eq(0), li:eq(2), li:eq(3)')
  +highlight-row('li:eq(1)')
  .notes: :t()
    Think about this in terms of the looking/search discrepancy ...

+slide
  +img('hood_2003_fig1.jpg')
  p.source Hood et al (2003, figure 1)
  .notes: :t()
    Recall the discrepancy in looking vs search measures.  
    What property of modules could help us to 
    explain it?








+slide
  +properties_of_modules
  +row-bkg('.limited-accessibility','grey')
  .notes To say that a system or module exhibits limited accessibility is to say that the representations in the system are not usually inferentially integrated with knowledge.
  .notes I think this is the key feature we need to assign to modular representations (=core knowledge) in order to explain the apparent discrepancies in the findings about when knowledge emerges in development.
  .notes: :t()
    Limited accessibility explains why the representations might drive looking but not reaching.
    But doesn't the bare appeal to limited accessibility leave open why the looking and not the searching (rather than conversely)?
    I think not, given the assumption that searching is purposive in a way that looking is not.  (Searching depends on practical reasoning.)
    We'll come back to this later (if core knowledge of objects involves object files, it's easier to see why it affects looking but not actions like reaching.)
  .notes: :t()
    Except, of course, calling this an explanation is too much.
    After all, limited accessibility is more or less what we're trying to explain.
    But this is the first problem --- the problem with the standard way of characterising modularity and core systems merely by listing features.


section.slide
  .notes: :t()
    Let me illustrate limited accessibility ...
  .notes: :t()
    Limited accessbility is a familar feature of many cognitive systems.
    When you grasp an object with a precision grip, it turns out that there is a very 
    reliable pattern.
    At a certain point in moving towards it your fingers will reach a maximum grip aperture 
    which is normally a certain amount wider than the object to be grasped, and then start to close.
    Now there's no physiological reason why grasping should work like this, rather than grip hand 
    closing only once you contact the object.
    Maximum grip aperture shows anticipation of the object: the mechanism responsible for 
    guiding your action does so by representing various things including some features of 
    the object.
    But we ordinarily have no idea about this.
    The discovery of how grasping is controlled depended on high speed photography.
    This is an illustration of limited accessibility.
    (This can also illustrate information encapsulation and domain specificity.)
  .container_12
    .grid_4
      .words
        p maximum grip aperture
        p.right (source: Jeannerod 2009, figure 10.1)
    .grid_8
      img(src='/img/jeannerod_2009_fig10-1.png', style='max-height:600px;')

+slide
  +img('glover_2002_fig1a.png')
  p.source Glover (2002, figure 1a)
  .notes: :t()
    Illusion affects planning but not control:
    information is in the system;
    information is not available to knowledge \citep{glover:2002_visual}.


+slide
  +img('hood_2003_fig1.jpg')
  p.source Hood et al (2003, figure 1)
  .notes: :t()
    Explain limited accessibility by analogy with maximum grip aperture.


+slide
  .notes Let me sum up
  p core system = module ?
  .notes: :t()
    I think it is reasonable to identify core systems with modules and to
    largely ignore what different people say in introducing these ideas.
    The theory is not strong enough to support lots of distinctions.
  .slide
    p.em-above modules are a ‘natural (functional?) kind’
    .notes: :t()
      If we are to overcome certain compelling challenges to the notion
      of modularity, we can't regard it as *defined* by a list of features;
      although we can suppose that it is characterised by them.
      This is because of the challenges we have seen:
  .slide
    p.em-above.notes.show Will the notion of modularity help us in meeting the 
      span.bkg-words-highlight-invert.challenges challenges
      span  to the very idea of a core system or module? 
    .notes Recall that the challenges were these:
    ul.notes.show.em-above
      li.bkg-grey-row multiple definitions
      li mismatch of definition to application 
      li.bkg-grey-row justification for definition by list-of-features
      li.bkg-grey-row definition by list-of-features rules out explanation
    .notes: :t()
      To deal with multiple definitions etc, we need modules as natural kinds.
    +unhighlight-row_('li:eq(0), li:eq(2), li:eq(3)')
    +highlight-row('li:eq(1)')
    .notes: :t()
      Our reason for wanting core knowledge or modular representation was to explain
      some discrepancies.
      The property that actually explains these is limited accessiblity (domain 
      specificity might be important too).  The other properties are simply
      irrelevant.  Particularly innateness.

+slide_middle
  p.center.notes.show Alternative: Messiness 
  .notes: :t()
    Discusss possibility of piecemeal view (attraction of core knowledge is that it 
    unifies different domains, but maybe we can't)
  .notes: :t()
    I'm inclined by a view that is both more piecemeal and more unifying:
    (a) modules cover a wider range of domains than Carey or Spelke think core systems 
    do (not just objects, number, geometry and the rest but also speech, colour
    and mental states)
    (b) there is less to say about what unifies any of these cases (maybe core knowledge
    of objects has more in common with, say, categorical perception of colour than
    with core knowledge of action.)
  .notes: :t()
    Certainly the notion of core knowledge or module doesn't save us from needing to look
    at particular mechanisms.
    I think that thinking about categorical perception, or the perceptual 
    systems that underpin objects indexes is a way of getting at what core knowledge really 
    involves.  Core systems are not always something over and above perceptual and motor systems
    (although it seems probably that they sometimes are if our competence with syntax rests on 
    core knowledge).

+slide_middle
  p.center The Core Knowledge View
  .notes: :t()
    I've been evaluating The Core Knowledge View, trying to explain
    the sorts of challenges that face it and the ways in which they might be 
    responded to.
  .slide
    .notes: :t()
      Anyone who accepts The Core Knowledge View has a problem:
    p.em-above.center.notes.show How do you get from  core knowledge (=modular representation) to knowledge knowledge?
    .notes: :t()
      The Core Knowledge View is the view that infants' competence with objects, causes, colours
      and the rest depends not on knowledge (as the Simple View has it) but on core knowledge.
    .notes: :t()
      Thos question is just a variant of what I called Our Next Problem (see lecture 2; it arises 
      from the failure of the Simple View).




